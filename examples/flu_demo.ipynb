{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/micha-grela/Pulpit/Praca/open-source/diagnostipy/dist/diagnostipy-0.1.2.tar.gz\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy<3.0.0,>=2.1.3 in /home/micha-grela/.cache/pypoetry/virtualenvs/diagnostipy-hz1xT1ew-py3.12/lib/python3.12/site-packages (from diagnostipy==0.1.2) (2.1.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.10.1 in /home/micha-grela/.cache/pypoetry/virtualenvs/diagnostipy-hz1xT1ew-py3.12/lib/python3.12/site-packages (from diagnostipy==0.1.2) (2.10.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/micha-grela/.cache/pypoetry/virtualenvs/diagnostipy-hz1xT1ew-py3.12/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.10.1->diagnostipy==0.1.2) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /home/micha-grela/.cache/pypoetry/virtualenvs/diagnostipy-hz1xT1ew-py3.12/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.10.1->diagnostipy==0.1.2) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /home/micha-grela/.cache/pypoetry/virtualenvs/diagnostipy-hz1xT1ew-py3.12/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.10.1->diagnostipy==0.1.2) (4.12.2)\n",
      "Building wheels for collected packages: diagnostipy\n",
      "  Building wheel for diagnostipy (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for diagnostipy: filename=diagnostipy-0.1.2-py3-none-any.whl size=13882 sha256=feb5ce39320161a198692753f604da5d212212adda862c2d26ba38510485224f\n",
      "  Stored in directory: /home/micha-grela/.cache/pip/wheels/6b/69/b1/d253370e251b5abc94a6b0c95a7233054a02be66358e738ba6\n",
      "Successfully built diagnostipy\n",
      "Installing collected packages: diagnostipy\n",
      "  Attempting uninstall: diagnostipy\n",
      "    Found existing installation: diagnostipy 0.1.2\n",
      "    Uninstalling diagnostipy-0.1.2:\n",
      "      Successfully uninstalled diagnostipy-0.1.2\n",
      "Successfully installed diagnostipy-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install ../dist/diagnostipy-0.1.2.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import math\n",
    "from diagnostipy.core.models.symptom_rule import SymptomRule\n",
    "from diagnostipy.core.ruleset import SymptomRuleset\n",
    "from diagnostipy.core.evaluator import Evaluator\n",
    "from diagnostipy.utils.enums import EvaluationFunctionEnum, ConfidenceFunctionEnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = [\n",
    "    SymptomRule(\n",
    "        name=\"High Fever\",\n",
    "        weight=7,\n",
    "        critical=False,\n",
    "        conditions={\"fever\"},\n",
    "        apply_condition=lambda data: data.get(\"fever\", 0) >= 38.0,\n",
    "    ),\n",
    "    SymptomRule(\n",
    "        name=\"Moderate Fever\",\n",
    "        weight=3,\n",
    "        critical=False,\n",
    "        conditions={\"fever\"},\n",
    "        apply_condition=lambda data: 37.5 <= data.get(\"fever\", 0) < 38.0,\n",
    "    ),\n",
    "    SymptomRule(\n",
    "        name=\"Persistent Cough\",\n",
    "        weight=8,\n",
    "        critical=False,\n",
    "        conditions={\"cough\"},\n",
    "    ),\n",
    "    SymptomRule(\n",
    "        name=\"Sore Throat\",\n",
    "        weight=4,\n",
    "        critical=False,\n",
    "        conditions={\"sore_throat\"},\n",
    "    ),\n",
    "    SymptomRule(\n",
    "        name=\"Fatigue\",\n",
    "        weight=3,\n",
    "        critical=False,\n",
    "        conditions={\"fatigue\"},\n",
    "    ),\n",
    "    SymptomRule(\n",
    "        name=\"High Fever with Fatigue\",\n",
    "        weight=10,\n",
    "        critical=True,\n",
    "        apply_condition=lambda data: data.get(\"fever\", 0) >= 38.0\n",
    "        and data.get(\"fatigue\", False),\n",
    "        conditions={\"fever\", \"fatigue\"},\n",
    "    ),\n",
    "]\n",
    "\n",
    "evaluator_settings = {\n",
    "    \"exclude_overlaps\": True,\n",
    "    \"evaluation_function\": EvaluationFunctionEnum.BINARY_SIMPLE,\n",
    "    \"confidence_function\": ConfidenceFunctionEnum.WEIGHTED,\n",
    "    \"score_function\": None,\n",
    "    \"score_threshold\": None,\n",
    "    \"labels\": None,\n",
    "    \"threshold_label_map\": None,\n",
    "}\n",
    "ruleset = SymptomRuleset(rules=rules, exclude_overlaps=evaluator_settings[\"exclude_overlaps\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_evaluator_settings(data: dict):\n",
    "    ruleset.exclude_overlaps = data[\"exclude_overlaps\"]\n",
    "    evaluator_settings[\"evaluation_function\"] = data[\"evaluation_function\"]\n",
    "    evaluator_settings[\"confidence_function\"] = data[\"confidence_function\"]\n",
    "\n",
    "def show_options(evaluation_function_value):\n",
    "    visibility = {\n",
    "        \"score_function\": False,\n",
    "        \"score_threshold\": False,\n",
    "        \"labels\": False,\n",
    "        \"threshold_label_map\": False,\n",
    "    }\n",
    "    if evaluation_function_value == EvaluationFunctionEnum.BINARY_SCORING_BASED.value:\n",
    "        visibility[\"score_function\"] = True\n",
    "        visibility[\"score_threshold\"] = True\n",
    "    elif evaluation_function_value == EvaluationFunctionEnum.MULTICLASS_SIMPLE.value:\n",
    "        visibility[\"labels\"] = True\n",
    "    elif evaluation_function_value == EvaluationFunctionEnum.MULTICLASS_SCORING_BASED.value:\n",
    "        visibility[\"labels\"] = True\n",
    "        visibility[\"threshold_label_map\"] = True\n",
    "\n",
    "    return (\n",
    "        gr.update(visible=visibility[\"score_function\"]),\n",
    "        gr.update(visible=visibility[\"score_threshold\"]),\n",
    "        gr.update(visible=visibility[\"labels\"]),\n",
    "        gr.update(visible=visibility[\"threshold_label_map\"]),\n",
    "    )\n",
    "\n",
    "SCORE_FUNCTIONS = {\n",
    "    \"identity\": lambda _: lambda score: score,\n",
    "    \"scale_by_0.1\": lambda _: lambda score: score * 0.1,\n",
    "    \"tanh\": lambda _: lambda score: math.tanh(score),\n",
    "    \"sigmoid\": lambda _: lambda score: 1 / (1 + math.exp(-score)),\n",
    "}\n",
    "def get_score_function(func_name):\n",
    "    score_function_factory = SCORE_FUNCTIONS.get(func_name)\n",
    "    if score_function_factory is None:\n",
    "        raise ValueError(f\"Invalid score function: {func_name}\")\n",
    "    return score_function_factory(None)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flu_diagnosis_demo(data, score_function=None, score_threshold=None, labels=None, threshold_label_map=None):\n",
    "    evaluator = Evaluator(\n",
    "        ruleset,\n",
    "        data=data,\n",
    "        evaluation_function=evaluator_settings[\"evaluation_function\"],\n",
    "        confidence_function=evaluator_settings[\"confidence_function\"],\n",
    "    )\n",
    "    \n",
    "    evaluator.evaluate(score_function=get_score_function(score_function), score_threshold=score_threshold, labels=labels, threshold_label_map=threshold_label_map)\n",
    "    applicable_rules = ruleset.get_applicable_rules(data)\n",
    "    result = evaluator.get_results()\n",
    "\n",
    "    output = {\n",
    "        \"Diagnosis\": result.label if hasattr(result, \"label\") else \"N/A\",\n",
    "        \"Total Score\": result.total_score if hasattr(result, \"total_score\") else \"N/A\",\n",
    "        \"Confidence\": result.confidence if hasattr(result, \"confidence\") else \"N/A\",\n",
    "        \"Applicable Rules\": [rule.name for rule in applicable_rules],\n",
    "    }\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnosis_tab():\n",
    "    with gr.Tab(\"Diagnosis\"):\n",
    "        gr.Markdown(\"# Flu Diagnosis with Diagnostipy - Interactive Demo\")\n",
    "        fever = gr.Number(label=\"What is your temperature? (Â°C)\", value=36.6, interactive=True)\n",
    "        cough = gr.Radio(choices=[\"True\", \"False\", \"Not Given\"], label=\"Do you have a persistent cough?\", value=\"Not Given\")\n",
    "        sore_throat = gr.Radio(choices=[\"True\", \"False\", \"Not Given\"], label=\"Do you have a sore throat?\", value=\"Not Given\")\n",
    "        fatigue = gr.Radio(choices=[\"True\", \"False\", \"Not Given\"], label=\"Do you feel fatigued?\", value=\"Not Given\")\n",
    "        result_output = gr.JSON(label=\"Results\")\n",
    "        evaluate_button = gr.Button(\"Evaluate\")\n",
    "\n",
    "        def gather_inputs(f, c, s, fa):\n",
    "            def parse_bool(value):\n",
    "                if value == \"True\":\n",
    "                    return True\n",
    "                elif value == \"False\":\n",
    "                    return False\n",
    "                return None \n",
    "\n",
    "            return {\n",
    "                \"fever\": f,\n",
    "                \"cough\": parse_bool(c),\n",
    "                \"sore_throat\": parse_bool(s),\n",
    "                \"fatigue\": parse_bool(fa),\n",
    "            }\n",
    "\n",
    "        evaluate_button.click(\n",
    "            lambda f, c, s, fa: flu_diagnosis_demo(\n",
    "                gather_inputs(f, c, s, fa),\n",
    "                score_function=evaluator_settings.get(\"score_function\"),\n",
    "                score_threshold=evaluator_settings.get(\"score_threshold\"),\n",
    "                labels=evaluator_settings.get(\"labels\"),\n",
    "                threshold_label_map=evaluator_settings.get(\"threshold_label_map\"),\n",
    "            ),\n",
    "            inputs=[fever, cough, sore_throat, fatigue],\n",
    "            outputs=result_output,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def settings_tab():\n",
    "    with gr.Tab(\"Settings\"):\n",
    "        gr.Markdown(\"# Configure Rules and Evaluator Settings\")\n",
    "\n",
    "        exclude_overlaps = gr.Checkbox(label=\"Exclude Overlapping Rules\", value=True)\n",
    "        evaluation_function = gr.Dropdown(\n",
    "            choices=[e.value for e in EvaluationFunctionEnum],\n",
    "            label=\"Evaluation Function\",\n",
    "            value=EvaluationFunctionEnum.BINARY_SIMPLE.value,\n",
    "            interactive=True,\n",
    "        )\n",
    "        confidence_function = gr.Dropdown(\n",
    "            choices=[c.value for c in ConfidenceFunctionEnum],\n",
    "            label=\"Confidence Function\",\n",
    "            value=ConfidenceFunctionEnum.WEIGHTED.value,\n",
    "            interactive=True,\n",
    "        )\n",
    "\n",
    "        score_function = gr.Dropdown(\n",
    "            choices=[\"identity\", \"scale_by_0.1\", \"tanh\", \"sigmoid\"],\n",
    "            label=\"Score Function\",\n",
    "            interactive=True,\n",
    "            visible=False,\n",
    "        )\n",
    "        score_threshold = gr.Number(\n",
    "            label=\"Score Threshold\",\n",
    "            value=0.5,\n",
    "            interactive=True,\n",
    "            visible=False,\n",
    "        )\n",
    "        labels = gr.Textbox(\n",
    "            label=\"Labels (comma-separated for multiclass)\",\n",
    "            value=\"Low,Medium,High\",\n",
    "            interactive=True,\n",
    "            visible=False,\n",
    "        )\n",
    "        threshold_label_map = gr.Textbox(\n",
    "            label=\"Threshold-Label Map (JSON format for multiclass)\",\n",
    "            value='{\"0.5\": \"Low\", \"1.0\": \"Medium\", \"1.5\": \"High\"}',\n",
    "            interactive=True,\n",
    "            visible=False,\n",
    "        )\n",
    "\n",
    "        evaluation_function.change(\n",
    "            show_options,\n",
    "            inputs=[evaluation_function],\n",
    "            outputs=[score_function, score_threshold, labels, threshold_label_map],\n",
    "        )\n",
    "\n",
    "        update_settings_button = gr.Button(\"Update Settings\")\n",
    "\n",
    "        def handle_update(eo, ef, cf, sf, st, lbls, tlm):\n",
    "            evaluator_settings.update({\n",
    "                \"exclude_overlaps\": eo,\n",
    "                \"evaluation_function\": EvaluationFunctionEnum(ef),\n",
    "                \"confidence_function\": ConfidenceFunctionEnum(cf),\n",
    "                \"score_function\": sf,\n",
    "                \"score_threshold\": st,\n",
    "                \"labels\": lbls.split(\",\") if lbls else None,\n",
    "                \"threshold_label_map\": eval(tlm) if tlm else None,\n",
    "            })\n",
    "\n",
    "        update_settings_button.click(\n",
    "            handle_update,\n",
    "            inputs=[\n",
    "                exclude_overlaps,\n",
    "                evaluation_function,\n",
    "                confidence_function,\n",
    "                score_function,\n",
    "                score_threshold,\n",
    "                labels,\n",
    "                threshold_label_map,\n",
    "            ],\n",
    "            outputs=None,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    diagnosis_tab()\n",
    "    settings_tab()\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diagnostipy-hz1xT1ew-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
